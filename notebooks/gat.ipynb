{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.nn.models import GAT\n",
    "\n",
    "#from model.extras.gat import GAT, GraphAttn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   6,   6,\n",
      "           6,   6,   6,   6,  13,  13,  13,  13,  13,  13,  13,  13,  13,  18,\n",
      "          18,  18,  18,  18,  18,  18,  18,  18,  18,  21,  21,  21,  21,  21,\n",
      "          21,  21,  21,  21,  21,  22,  22,  22,  22,  22,  22,  22,  22,  22,\n",
      "          31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  32,  42,\n",
      "          42,  42,  42,  42,  42,  42,  42,  42,  43,  43,  43,  43,  43,  43,\n",
      "          43,  43,  43,  43,  50,  50,  50,  53,  53,  53,  53,  53,  53,  53,\n",
      "          60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n",
      "          60,  60,  60,  60,  60,  61,  61,  61,  61,  61,  61,  61,  61,  61,\n",
      "          61,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  77,  77,  77,\n",
      "          77,  77,  77,  77,  80,  80,  80,  80,  80,  80,  80,  80,  80,  81,\n",
      "          81,  81,  81,  81,  81,  81,  81,  81,  81,  84,  84,  84,  84,  84,\n",
      "          84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,  84,\n",
      "          84,  84,  88,  88,  88,  88,  88,  88,  88,  88,  88,  88,  89,  89,\n",
      "          89,  89,  89,  89,  89,  89,  89,  89,  89,  90,  90,  90,  90,  90,\n",
      "          90,  90,  90,  90,  90, 103, 103, 103, 103, 103, 103],\n",
      "        [ 60,  84,  13,  18,  21,  22,  60,  76,  77,  80,  81,  84,  31,  60,\n",
      "          84,  88,  89,  90,   1,  18,  21,  22,  60,  76,  77,  81,  84,   1,\n",
      "          13,  21,  22,  60,  76,  77,  80,  81,  84,   1,  13,  18,  22,  60,\n",
      "          76,  77,  80,  81,  84,   1,  13,  18,  21,  60,  76,  77,  81,  84,\n",
      "           6,  42,  43,  60,  61,  76,  80,  84,  88,  89,  90, 103,  80,  31,\n",
      "          43,  53,  60,  61,  84,  88,  89,  90,  31,  42,  53,  60,  61,  84,\n",
      "          88,  89,  90, 103,   1,  60,  84,  42,  43,  61,  84,  88,  89,  90,\n",
      "           0,   1,   6,  13,  18,  21,  22,  31,  42,  43,  61,  76,  80,  81,\n",
      "          84,  88,  89,  90, 103,  31,  42,  43,  53,  60,  84,  88,  89,  90,\n",
      "         103,   1,  13,  18,  21,  22,  31,  60,  80,  81,  84,   1,  13,  18,\n",
      "          21,  22,  81,  84,   1,  18,  21,  31,  32,  60,  76,  81,  84,   1,\n",
      "          13,  18,  21,  22,  60,  76,  77,  80,  84,   0,   1,   6,  13,  18,\n",
      "          21,  22,  31,  42,  43,  53,  60,  61,  76,  77,  80,  81,  88,  89,\n",
      "          90, 103,   6,  31,  42,  43,  53,  60,  61,  84,  89,  90,   6,  31,\n",
      "          42,  43,  53,  60,  61,  84,  88,  90, 103,   6,  31,  42,  43,  53,\n",
      "          60,  61,  84,  88,  89,  31,  43,  60,  61,  84,  89]])\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix = torch.load('./data/scene_graphs/0.pt')[0]\n",
    "\n",
    "edge_index = adjacency_matrix.nonzero(as_tuple=False).t().long()\n",
    "print(edge_index)\n",
    "\n",
    "\n",
    "#sg = Data(traj_sgs_tensor)\n",
    "#sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "tensor([[ 30,  30,  30,  30,  30,  30,  30,  30,  30,  34,  34,  34,  34,  34,\n",
      "          35,  35,  35,  35,  35,  35,  35,  54,  54,  54,  54,  54,  54,  54,\n",
      "          54,  54,  54,  54,  60,  60,  60,  60,  60,  60,  60,  60,  60,  60,\n",
      "          60,  60,  60,  60,  60,  64,  64,  64,  64,  64,  64,  64,  66,  66,\n",
      "          66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  66,  71,  71,  71,\n",
      "          71,  71,  71,  71,  71,  71,  71,  82,  82,  82,  82,  82,  88,  88,\n",
      "          88,  88,  88,  88,  88,  88,  88,  88,  88,  88,  88,  91,  91,  91,\n",
      "          91,  91,  91,  91, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "         101, 102, 102, 102, 102, 107, 107, 107, 107, 107, 107, 116, 116, 116,\n",
      "         116, 116, 116, 116, 116, 134, 134, 134, 134, 134, 134, 134, 142, 142,\n",
      "         142, 142, 142, 142, 142],\n",
      "        [ 54,  60,  66,  88,  91, 101, 116, 134, 142,  54,  60,  71, 101, 126,\n",
      "          54,  60,  66,  71,  88, 101, 116,  30,  35,  60,  64,  66,  71,  82,\n",
      "          88, 101, 107, 116,  30,  35,  54,  64,  66,  71,  82,  88,  91, 101,\n",
      "         102, 107, 116, 134, 142,  54,  60,  66,  71,  82,  88, 101,  30,  35,\n",
      "          54,  60,  64,  71,  88,  91, 101, 107, 116, 134, 142,  35,  54,  60,\n",
      "          64,  66,  82,  88, 101, 107, 116,  54,  60,  64,  71, 101,  30,  35,\n",
      "          54,  60,  64,  66,  71,  91, 101, 107, 116, 134, 142,  30,  60,  66,\n",
      "          88, 102, 134, 142,  30,  35,  54,  60,  64,  66,  71,  82,  88, 107,\n",
      "         116,  60,  91, 134, 142,  54,  60,  66,  71,  88, 101,  30,  35,  54,\n",
      "          60,  66,  71,  88, 101,  30,  60,  66,  88,  91, 102, 142,  30,  60,\n",
      "          66,  88,  91, 102, 134]])\n",
      "145\n",
      "152\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n",
      "          2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,\n",
      "          6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "          9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
      "         11, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
      "         14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17,\n",
      "         17],\n",
      "        [ 3,  4,  6,  9, 10, 11, 14, 16, 17,  3,  4,  7, 11, 15,  3,  4,  6,  7,\n",
      "          9, 11, 14,  0,  2,  4,  5,  6,  7,  8,  9, 11, 13, 14,  0,  2,  3,  5,\n",
      "          6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 17,  3,  4,  6,  7,  8,  9, 11,\n",
      "          0,  2,  3,  4,  5,  7,  9, 10, 11, 13, 14, 16, 17,  2,  3,  4,  5,  6,\n",
      "          8,  9, 11, 13, 14,  3,  4,  5,  7, 11,  0,  2,  3,  4,  5,  6,  7, 10,\n",
      "         11, 13, 14, 16, 17,  0,  4,  6,  9, 12, 16, 17,  0,  2,  3,  4,  5,  6,\n",
      "          7,  8,  9, 13, 14,  4, 10, 16, 17,  3,  4,  6,  7,  9, 11,  0,  2,  3,\n",
      "          4,  6,  7,  9, 11,  0,  4,  6,  9, 10, 12, 17,  0,  4,  6,  9, 10, 12,\n",
      "         16]])\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse, remove_isolated_nodes, mask_select\n",
    "\n",
    "# Step 1: Create an adjacency matrix (example)\n",
    "test = torch.tensor([[0, 2, 1],\n",
    "                                  [5, 0, 0],\n",
    "                                  [8, 0, 0]], dtype=torch.float)\n",
    "\n",
    "#adjacency_matrix = torch.load('./data/scene_graphs/19.pt')[20]\n",
    "adjacency_matrix = torch.load('./data/scene_graphs/19.pt')[0]\n",
    "\n",
    "# Step 2: Convert the adjacency matrix to edge_index\n",
    "# Get the indices where the adjacency matrix is non-zero\n",
    "#edge_index = adjacency_matrix.nonzero(as_tuple=False).t().long()\n",
    "#edge_attr = [adjacency_matrix[edge_index[0][i]][edge_index[1][i]] for i in range(len(edge_index[0]))]\n",
    "edge_index, edge_attr = dense_to_sparse(adjacency_matrix)\n",
    "\n",
    "# Step 3: Create node features (example: using a feature size of 1)\n",
    "num_nodes = adjacency_matrix.size(0)\n",
    "node_features = torch.randn(num_nodes, 1)  # Random features for each node\n",
    "\n",
    "edge_index, edge_attr, mask = remove_isolated_nodes(edge_index, edge_attr)\n",
    "node_features = mask_select(node_features, 0, mask)\n",
    "\n",
    "# Step 4: Create the PyG Data object\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "print(num_nodes)\n",
    "print(edge_index)\n",
    "print(len(edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_852460/2241869286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nuscenes/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "a = torch.ones(5, 5)*1\n",
    "b = torch.ones(3, 5)*2\n",
    "c = torch.ones(2, 5)*3\n",
    "padded = pad_sequence([a, b, c],batch_first=True)\n",
    "print(padded.size())\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_geometric_polygon_layers = ['drivable_area', 'road_segment', 'road_block', 'lane', 'ped_crossing',\n",
    "                                             'walkway', 'stop_line', 'carpark_area']\n",
    "non_geometric_line_layers = ['road_divider', 'lane_divider', 'traffic_light']\n",
    "non_geometric_layers = non_geometric_polygon_layers+non_geometric_line_layers\n",
    "len(non_geometric_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "categories = [['animal', 'human', 'movable_object', 'static_object', 'vehicle'], \n",
    "              ['pedestrian', 'barrier', 'debris', 'pushable_pullable', 'trafficcone', 'bicycle_rack', 'bicycle', 'bus', 'car', 'construction', 'emergency', 'motorcycle', 'trailer', 'truck'],\n",
    "              ['adult', 'child', 'construction_worker', 'personal_mobility', 'police_officer', 'stroller', 'wheelchair', 'bendy', 'rigid', 'ambulance', 'police']]\n",
    "\n",
    "length = sum(len(c) for c in categories)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5\n",
      "[(2.0, 3.333333333333333)]\n",
      "20.0\n",
      "[(3.0, 3.3333333333333335)]\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import shapely\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "single = Polygon([[0,5], [1,0], [5,5]])\n",
    "single2 = Polygon([[8,5], [1,0], [5,5]])\n",
    "print(single.area)\n",
    "print(list(single.centroid.coords))\n",
    "\n",
    "multi = MultiPolygon([single, single2])\n",
    "print(multi.area)\n",
    "print(list(multi.centroid.coords))\n",
    "print(multi.centroid.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 30])\n",
      "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "a = torch.ones(5, 30)\n",
    "b = torch.ones(2, 30)\n",
    "c = torch.ones(1, 30)\n",
    "d = pad_sequence([a, b, c])\n",
    "print(d.size())\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2453]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "a = np.zeros(2500)\n",
    "l = []\n",
    "for i in range(2454):\n",
    "    data_path = '/data/Datasets/nuscenes_custom/data/actions/'\n",
    "    path = data_path + str(i) + '.pt'\n",
    "    if not os.path.exists(path):\n",
    "        a[i] = 1\n",
    "        l.append(i)\n",
    "\n",
    "print(len(l))\n",
    "print(l)\n",
    "a[950:1100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2453, 2453]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "step = 3\n",
    "intervals = []\n",
    "for i in range(0, len(l), step):\n",
    "    intervals.append([l[i], l[min(i+step, len(l)-1)]])\n",
    "print(intervals)\n",
    "print(len(intervals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "a = torch.zeros([5,5])\n",
    "a[1,0] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_utils import *\n",
    "def encode_edges(self, edge_attr):\n",
    "        encodings = []\n",
    "        for e in edge_attr:\n",
    "            one_hot = torch.eye(len(edge_labels))[e]\n",
    "            encodings.append(one_hot)\n",
    "        return torch.stack(encodings)\n",
    "\n",
    "encode_edges []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Assume data_list is your list of PyG Data objects\n",
    "data_list = [Data(), Data()]  # Example list of Data objects\n",
    "\n",
    "# Save the list of Data objects\n",
    "torch.save(data_list, 'data_list.pt')\n",
    "\n",
    "# Load the list of Data objects\n",
    "loaded_data_list = torch.load('data_list.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hgfhsdjlgdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3782381/391165604.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhgfhsdjlgdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hgfhsdjlgdf' is not defined"
     ]
    }
   ],
   "source": [
    "type(loaded_data_list[0])\n",
    "hgfhsdjlgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2399]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "l = []\n",
    "for i in range(2450):\n",
    "    if not os.path.exists('/data/Datasets/nuscenes_custom/data/scene_graphs_pyg/'+str(i)+'.pt'):\n",
    "        l.append(i)\n",
    "print(len(l))\n",
    "print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuscenes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
